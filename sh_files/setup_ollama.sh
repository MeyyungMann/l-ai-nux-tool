#!/bin/bash

echo "ğŸš€ Setting up Ollama in Docker container..."
echo "============================================="

# Start Ollama service in background
echo "ğŸ“¡ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to start
echo "â³ Waiting for Ollama to start..."
sleep 5

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âŒ Failed to start Ollama service"
    exit 1
fi

echo "âœ… Ollama service started successfully!"

# Pull GPT-OSS model if not already present
echo "ğŸ“¥ Checking for GPT-OSS model..."
if ! ollama list | grep -q "gpt-oss:20b"; then
    echo "ğŸ“¥ Pulling GPT-OSS 20B model..."
    ollama pull gpt-oss:20b
    echo "âœ… GPT-OSS model pulled successfully!"
else
    echo "âœ… GPT-OSS model already available!"
fi

echo ""
echo "ğŸ¯ Ollama setup complete!"
echo "ğŸŒ Ollama API: http://localhost:11434"
echo "ğŸ¤– Available models:"
ollama list

echo ""
echo "ğŸ’¡ You can now use Ollama mode in L-AI-NUX-TOOL!"
echo "   python gen_cmd.py --mode ollama 'your command description'"
