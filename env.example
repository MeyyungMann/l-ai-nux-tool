# L-AI-NUX-TOOL Environment Configuration
# Copy this file to .env and fill in your actual values

# ============================================
# ONLINE MODE CONFIGURATION
# ============================================

# OpenAI API Key (for online mode)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# API Configuration (optional - defaults shown)
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-3.5-turbo

# ============================================
# ALTERNATIVE PROVIDERS
# ============================================

# For Local Ollama (free, runs locally)
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_MODEL=llama2
# OPENAI_API_KEY=ollama

# For Azure OpenAI
# OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
# OPENAI_MODEL=gpt-35-turbo
# OPENAI_API_KEY=your-azure-api-key

# For LiteLLM Proxy
# OPENAI_BASE_URL=http://localhost:4000
# OPENAI_API_KEY=your-litellm-key

# ============================================
# MODE CONFIGURATION
# ============================================

# Default mode: online or offline
# MODE=offline

# ============================================
# INSTRUCTIONS
# ============================================
# 1. Copy this file: cp env.example .env
# 2. Edit .env with your actual API key
# 3. Never commit .env to git (it's in .gitignore)
# 4. Restart the application after changes
